{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sergioq2/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('traumamlcompetition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = []\n",
    "for _ in bucket.objects.filter(Prefix='images_1/augmented_images/'):\n",
    "    name = _.key\n",
    "    name = name.split('/')[2]\n",
    "    names_1.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_0 = []\n",
    "for _ in bucket.objects.filter(Prefix='images_0/images_0/'):\n",
    "    name = _.key\n",
    "    name = name.split('/')[2]\n",
    "    names_0.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_s3_image(s3_url):\n",
    "    s3_bucket = s3_url.split('/')[2]\n",
    "    s3_key = '/'.join(s3_url.split('/')[3:])\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "    image_data = response['Body'].read()\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_imagenes_1 = \"s3://traumamlcompetition/images_1/augmented_images/\"\n",
    "directorio_imagenes_0 = \"s3://traumamlcompetition/images_0/images_0/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((128, 128)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0., std=1.) \n",
    "])\n",
    "\n",
    "data = [(os.path.join(directorio_imagenes_1, filename), 1) for filename in names_1] + [(os.path.join(directorio_imagenes_0, filename), 0) for filename in names_0]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        \n",
    "        img_data = open_s3_image(img_path)\n",
    "        image = Image.open(BytesIO(img_data))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.float32) \n",
    "\n",
    "        return image, label\n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size=0.15, random_state=42, stratify=[label for _, label in data])\n",
    "\n",
    "train_dataset = CustomDataset(data_train, transform=transform)\n",
    "test_dataset = CustomDataset(data_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sergioq2/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sergioq2/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = 'traumamlcompetition'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    images.append(image.numpy())  # Convierte el tensor de imagen a un array numpy\n",
    "    labels.append(label.numpy())  # Convierte el tensor de etiqueta a un array numpy\n",
    "\n",
    "csv_filename = 'dataset.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(zip(images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    images.append(image.numpy()) \n",
    "    labels.append(label.numpy()) \n",
    "\n",
    "# Escribir los datos en un archivo CSV\n",
    "csv_filename = 'dataset_test.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(zip(images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://traumamlcompetition/sagemaker/datacontainer/dataset.csv\n",
      "s3://traumamlcompetition/sagemaker/datacontainer/dataset_test.csv\n"
     ]
    }
   ],
   "source": [
    "sk_prefix = \"sagemaker/datacontainer\"\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"dataset.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"dataset_test.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")\n",
    "print(trainpath)\n",
    "print(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normaliza los datos si es necesario\n",
    "])\n",
    "\n",
    "local_train_dataset = CustomDataset(train_dataset, transform=transform)\n",
    "local_test_dataset = CustomDataset(test_dataset, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(local_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(local_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from io import BytesIO\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, trial, num_conv_layers, num_filters, num_neurons, drop_conv2, drop_fc1):\n",
    "        super(Net, self).__init__()                                                     # Initialize parent class\n",
    "        in_size = 264                                                                    # Input image size (28 pixels)\n",
    "        kernel_size = 3                                                                 # Convolution filter size\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, num_filters[0], kernel_size=(3, 3))])  # List with the Conv layers\n",
    "        out_size = in_size - kernel_size + 1                                            # Size of the output kernel\n",
    "        out_size = int(out_size / 2)                                                    # Size after pooling\n",
    "        for i in range(1, num_conv_layers):\n",
    "            self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=(3, 3)))\n",
    "            out_size = out_size - kernel_size + 1                                       # Size of the output kernel\n",
    "            out_size = int(out_size/2)                                                  # Size after pooling\n",
    "\n",
    "        self.conv2_drop = nn.Dropout2d(p=drop_conv2)                                    # Dropout for conv2\n",
    "        self.out_feature = num_filters[num_conv_layers-1] * out_size * out_size         # Size of flattened features\n",
    "        self.fc1 = nn.Linear(self.out_feature, num_neurons)                             # Fully Connected layer 1\n",
    "        self.fc2 = nn.Linear(num_neurons, 1)                                           # Fully Connected layer 2\n",
    "        self.p1 = drop_fc1                                                              # Dropout ratio for FC1\n",
    "\n",
    "        # Initialize weights with the He initialization\n",
    "        for i in range(1, num_conv_layers):\n",
    "            nn.init.kaiming_normal_(self.convs[i].weight, nonlinearity='relu')\n",
    "            if self.convs[i].bias is not None:\n",
    "                nn.init.constant_(self.convs[i].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv_i in enumerate(self.convs):  # For each convolutional layer\n",
    "            if i == 2:  # Add dropout if layer 2\n",
    "                x = F.relu(F.max_pool2d(self.conv2_drop(conv_i(x)), 2))  # Conv_i, dropout, max-pooling, RelU\n",
    "            else:\n",
    "                x = F.relu(F.max_pool2d(conv_i(x), 2))                   # Conv_i, max-pooling, RelU\n",
    "\n",
    "        x = x.view(x.size(0), -1)                     # Flatten tensor\n",
    "        x = F.relu(self.fc1(x))                              # FC1, RelU\n",
    "        x = F.dropout(x, p=self.p1, training=self.training)  # Apply dropout after FC1 only when training\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x           \n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, optimizer):\n",
    "    num_epochs = 16\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterio(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "def test(network):\n",
    "    network.eval()         # Set the module in evaluation mode (only affects certain modules)\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = network(images)\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "    accuracy_test = correct / len(test_loader.dataset)\n",
    "\n",
    "    return accuracy_test\n",
    "\n",
    "def objective(trial):\n",
    "    # Define range of values to be tested for the hyperparameters\n",
    "    num_conv_layers = trial.suggest_int(\"num_conv_layers\", 2, 3)  # Number of convolutional layers\n",
    "    num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16))\n",
    "                   for i in range(num_conv_layers)]              # Number of filters for the convolutional layers\n",
    "    num_neurons = trial.suggest_int(\"num_neurons\", 10, 260, 10)  # Number of neurons of FC1 layer\n",
    "    drop_conv2 = trial.suggest_float(\"drop_conv2\", 0.2, 0.5)     # Dropout for convolutional layer 2\n",
    "    drop_fc1 = trial.suggest_float(\"drop_fc1\", 0.2, 0.5)         # Dropout for FC1 layer\n",
    "\n",
    "    # Generate the model\n",
    "    model = Net(trial, num_conv_layers, num_filters, num_neurons, drop_conv2,  drop_fc1).to(device)\n",
    "\n",
    "    # Generate the optimizers\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])  # Optimizers\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)                                 # Learning rates\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training of the model\n",
    "    for epoch in range(n_epochs):\n",
    "        train(model, optimizer)  # Train the model\n",
    "        accuracy = test(model)   # Evaluate the model\n",
    "\n",
    "        # For pruning (stops trial early if not promising)\n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Parameters ----------------------------------------------------------\n",
    "    n_epochs = 10                         # Number of training epochs\n",
    "    batch_size_train = 64                 # Batch size for training data\n",
    "    batch_size_test = 64               # Batch size for testing data\n",
    "    number_of_trials = 60                # Number of Optuna trials\n",
    "    limit_obs = True                      # Limit number of observations for faster computation\n",
    "\n",
    "\n",
    "    if limit_obs:  # Limit number of observations\n",
    "        number_of_train_examples = 5 * batch_size_train  # Max train observations\n",
    "        number_of_test_examples = 2 * batch_size_test      # Max test observations\n",
    "    else:\n",
    "        number_of_train_examples = 60                   # Max train observations\n",
    "        number_of_test_examples = 10                    # Max test observations\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Make runs repeatable\n",
    "    random_seed = 1\n",
    "    torch.backends.cudnn.enabled = False  # Disable cuDNN use of nondeterministic algorithms\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    # Create directory 'files', if it doesn't exist, to save the dataset\n",
    "    directory_name = 'files'\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.mkdir(directory_name)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "    # Create an Optuna study to maximize test accuracy\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=number_of_trials)\n",
    "\n",
    "    # Find number of pruned and completed trials\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    # Display the study statistics\n",
    "    print(\"\\nStudy statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    trial = study.best_trial\n",
    "    print(\"Best trial:\")\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # Save results to csv file\n",
    "    df = study.trials_dataframe().drop(['datetime_start', 'datetime_complete', 'duration'], axis=1)  # Exclude columns\n",
    "    df = df.loc[df['state'] == 'COMPLETE']        # Keep only results that did not prune\n",
    "    df = df.drop('state', axis=1)                 # Exclude state column\n",
    "    df = df.sort_values('value')                  # Sort based on accuracy\n",
    "    df.to_csv('optuna_results.csv', index=False)  # Save to csv file\n",
    "\n",
    "    # Display results in a dataframe\n",
    "    print(\"\\nOverall Results (ordered by accuracy):\\n {}\".format(df))\n",
    "\n",
    "    # Find the most important hyperparameters\n",
    "    most_important_parameters = optuna.importance.get_param_importances(study, target=None)\n",
    "\n",
    "    # Display the most important hyperparameters\n",
    "    print('\\nMost important hyperparameters:')\n",
    "    for key, value in most_important_parameters.items():\n",
    "        print('  {}:{}{:.2f}%'.format(key, (15-len(key))*' ', value*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sergioq2/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pt_estimator = PyTorch(\n",
    "    entry_point=\"script.py\",\n",
    "    role='arn:aws:iam::646932767172:role/service-role/AmazonSageMaker-ExecutionRole-20230923T203035',\n",
    "    framework_version=\"1.4.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=2,\n",
    "    output_path='s3://traumamlcompetition/',\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    instance_type=\"ml.c5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-02-17-58-26-404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 17:58:28 Starting - Starting the training job...\n",
      "2023-10-02 17:58:43 Starting - Preparing the instances for training......\n",
      "2023-10-02 17:59:47 Downloading - Downloading input data...\n",
      "2023-10-02 18:00:22 Training - Downloading the training image..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-10-02 18:00:42,662 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-10-02 18:00:42,666 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:42,678 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-10-02 18:00:42,680 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-10-02 18:00:42,838 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "Generating setup.py\n",
      "2023-10-02 18:00:42,838 sagemaker-containers INFO     Generating setup.cfg\n",
      "2023-10-02 18:00:42,838 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "2023-10-02 18:00:42,838 sagemaker-containers INFO     Installing module with the following command:\n",
      "/opt/conda/bin/python3.6 -m pip install . \n",
      "Processing /tmp/tmpv5ataap_/module_dir\n",
      "Building wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9078 sha256=0def05432c4fb336ab7bbcab63bf39dc0a082cd983bc6adc40a827accc920954\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wsigl5id/wheels/ae/0d/43/ec66de04a77b3c8f07621cbccd54a786a6be59216a976a1b45\n",
      "Successfully built default-user-module-name\n",
      "Installing collected packages: default-user-module-name\n",
      "Successfully installed default-user-module-name-1.0.0\n",
      "2023-10-02 18:00:44,799 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:44,812 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:44,825 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:44,835 sagemaker-containers INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2023-10-02-17-58-26-404\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=script.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_MODULE_NAME=script\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2023-10-02-17-58-26-404\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.6 script.py\n",
      "2023-10-02 18:00:46,748 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2023-10-02 18:00:46,748 sagemaker-training-toolkit ERROR    framework error: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_training/trainer.py\", line 85, in train\n",
      "    entrypoint()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 99, in main\n",
      "    train(framework.training_env())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 60, in train\n",
      "    six.reraise(info[0], err, info[2])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 53, in train\n",
      "    capture_error=True, runner=framework.runner.ProcessRunnerType)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/entry_point.py\", line 100, in run\n",
      "    wait, capture_error\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 112, in run\n",
      "    cmd, _errors.ExecuteUserScriptError, capture_error=capture_error, cwd=_env.code_dir\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 50, in check_error\n",
      "    raise error_class(return_code=return_code, cmd=\" \".join(cmd), output=stderr)\n",
      "sagemaker_containers._errors.ExecuteUserScriptError: ExecuteUserScriptError:\n",
      "Command \"/opt/conda/bin/python3.6 script.py\"\n",
      "Traceback (most recent call last):\n",
      "  File \"script.py\", line 16, in <module>\n",
      "    import optuna\n",
      "ModuleNotFoundError: No module named 'optuna'\n",
      "ExecuteUserScriptError:\n",
      "Command \"/opt/conda/bin/python3.6 script.py\"\n",
      "Traceback (most recent call last):\n",
      "  File \"script.py\", line 16, in <module>\n",
      "    import optuna\n",
      "ModuleNotFoundError: No module named 'optuna'\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-10-02 18:00:44,938 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-10-02 18:00:44,941 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:44,951 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-10-02 18:00:44,953 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-10-02 18:00:45,085 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "Generating setup.py\n",
      "2023-10-02 18:00:45,085 sagemaker-containers INFO     Generating setup.cfg\n",
      "2023-10-02 18:00:45,085 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "2023-10-02 18:00:45,086 sagemaker-containers INFO     Installing module with the following command:\n",
      "/opt/conda/bin/python3.6 -m pip install . \n",
      "Processing /tmp/tmpm8msmfum/module_dir\n",
      "Building wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9078 sha256=a1f60d38f35f00ce8db4728da5ec291fca0baea5020fa4ecaf90115468dc3de9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dcgbmgru/wheels/f9/38/0f/742fb5c854dea61e2a91bf196a9970c101522755750bf7cdd1\n",
      "Successfully built default-user-module-name\n",
      "Installing collected packages: default-user-module-name\n",
      "Successfully installed default-user-module-name-1.0.0\n",
      "2023-10-02 18:00:46,933 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:46,945 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:46,957 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2023-10-02 18:00:46,967 sagemaker-containers INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-10-02-17-58-26-404\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=script.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=script\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-10-02-17-58-26-404\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://traumamlcompetition/pytorch-training-2023-10-02-17-58-26-404/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.6 script.py\n",
      "2023-10-02 18:00:48,687 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2023-10-02 18:00:48,687 sagemaker-training-toolkit ERROR    framework error: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_training/trainer.py\", line 85, in train\n",
      "    entrypoint()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 99, in main\n",
      "    train(framework.training_env())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 60, in train\n",
      "    six.reraise(info[0], err, info[2])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 53, in train\n",
      "    capture_error=True, runner=framework.runner.ProcessRunnerType)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/entry_point.py\", line 100, in run\n",
      "    wait, capture_error\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 112, in run\n",
      "    cmd, _errors.ExecuteUserScriptError, capture_error=capture_error, cwd=_env.code_dir\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 50, in check_error\n",
      "    raise error_class(return_code=return_code, cmd=\" \".join(cmd), output=stderr)\n",
      "sagemaker_containers._errors.ExecuteUserScriptError: ExecuteUserScriptError:\n",
      "Command \"/opt/conda/bin/python3.6 script.py\"\n",
      "Traceback (most recent call last):\n",
      "  File \"script.py\", line 16, in <module>\n",
      "    import optuna\n",
      "ModuleNotFoundError: No module named 'optuna'\n",
      "ExecuteUserScriptError:\n",
      "Command \"/opt/conda/bin/python3.6 script.py\"\n",
      "Traceback (most recent call last):\n",
      "  File \"script.py\", line 16, in <module>\n",
      "    import optuna\n",
      "ModuleNotFoundError: No module named 'optuna'\n",
      "\n",
      "2023-10-02 18:01:00 Uploading - Uploading generated training model\n",
      "2023-10-02 18:01:00 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2023-10-02-17-58-26-404: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_training/trainer.py\", line 85, in train\n    entrypoint()\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 99, in main\n    train(framework.training_env())\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 60, in train\n    six.reraise(info[0], err, info[2])\n  File \"/opt/conda/lib/python3.6/site-packages/six.py\", line 703, in reraise\n    raise value\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 53, in train\n    capture_error=True, runner=framework.runner.ProcessRunnerType)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/entry_point.py\", line 100, in run\n    wait, capture_error\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 112, in run\n    cmd, _errors.ExecuteUserScriptError, capture_error=captur",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/AI/sagemaker/sagemaker.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/AI/sagemaker/sagemaker.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pt_estimator\u001b[39m.\u001b[39;49mfit({\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m: trainpath, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m: testpath}, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/estimator.py:1314\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1313\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 1314\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_training_job\u001b[39m.\u001b[39;49mwait(logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/estimator.py:2597\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[39m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2597\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mlogs_for_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjob_name, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, log_type\u001b[39m=\u001b[39;49mlogs)\n\u001b[1;32m   2598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2599\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mwait_for_job(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/session.py:4868\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   4847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlogs_for_job\u001b[39m(\u001b[39mself\u001b[39m, job_name, wait\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, poll\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, log_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll\u001b[39m\u001b[39m\"\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   4848\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   4849\u001b[0m \n\u001b[1;32m   4850\u001b[0m \u001b[39m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4866\u001b[0m \u001b[39m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   4867\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4868\u001b[0m     _logs_for_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboto_session, job_name, wait, poll, log_type, timeout)\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/session.py:6788\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   6785\u001b[0m             last_profiler_rule_statuses \u001b[39m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   6787\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 6788\u001b[0m     _check_job_status(job_name, description, \u001b[39m\"\u001b[39;49m\u001b[39mTrainingJobStatus\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   6789\u001b[0m     \u001b[39mif\u001b[39;00m dot:\n\u001b[1;32m   6790\u001b[0m         \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/AI/sagemaker/sm/lib/python3.10/site-packages/sagemaker/session.py:6841\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCapacityError\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(reason):\n\u001b[1;32m   6836\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mCapacityError(\n\u001b[1;32m   6837\u001b[0m         message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   6838\u001b[0m         allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   6839\u001b[0m         actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   6840\u001b[0m     )\n\u001b[0;32m-> 6841\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6842\u001b[0m     message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   6843\u001b[0m     allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   6844\u001b[0m     actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   6845\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2023-10-02-17-58-26-404: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_training/trainer.py\", line 85, in train\n    entrypoint()\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 99, in main\n    train(framework.training_env())\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 60, in train\n    six.reraise(info[0], err, info[2])\n  File \"/opt/conda/lib/python3.6/site-packages/six.py\", line 703, in reraise\n    raise value\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_container/training.py\", line 53, in train\n    capture_error=True, runner=framework.runner.ProcessRunnerType)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/entry_point.py\", line 100, in run\n    wait, capture_error\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_containers/_process.py\", line 112, in run\n    cmd, _errors.ExecuteUserScriptError, capture_error=captur"
     ]
    }
   ],
   "source": [
    "pt_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
